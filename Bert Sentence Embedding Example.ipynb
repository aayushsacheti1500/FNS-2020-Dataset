{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.tokenization_bert.BertTokenizer at 0x191c996d828>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The financial performance of the company was average overall, but revenue spiked by a lot \" \\\n",
    "       \"There was a dip in the net profit margin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The financial performance of the company was average overall, but revenue spiked by a lot There was a dip in the net profit margin'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "the           1,996\n",
      "financial     3,361\n",
      "performance   2,836\n",
      "of            1,997\n",
      "the           1,996\n",
      "company       2,194\n",
      "was           2,001\n",
      "average       2,779\n",
      "overall       3,452\n",
      ",             1,010\n",
      "but           2,021\n",
      "revenue       6,599\n",
      "spiked       25,362\n",
      "by            2,011\n",
      "a             1,037\n",
      "lot           2,843\n",
      "there         2,045\n",
      "was           2,001\n",
      "a             1,037\n",
      "dip          16,510\n",
      "in            1,999\n",
      "the           1,996\n",
      "net           5,658\n",
      "profit        5,618\n",
      "margin        7,785\n",
      "[SEP]           102\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "count = 0\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Mark each of the 27 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print(segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 27\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = hidden_states[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Type of hidden_states:  <class 'tuple'>\n",
      "Tensor shape for each layer:  torch.Size([1, 27, 768])\n"
     ]
    }
   ],
   "source": [
    "# `hidden_states` is a Python list.\n",
    "print('      Type of hidden_states: ', type(hidden_states))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 27, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 27, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 13, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 27 x 3072\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 27 x 768\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.4926e-01, -4.5831e-01, -3.0521e-02,  2.6990e-01, -2.7917e-01,\n",
       "        -9.0261e-02, -3.3638e-01,  6.3047e-01, -1.3263e-01,  1.3970e-01,\n",
       "         5.0323e-01, -2.2278e-01,  6.3738e-01,  5.1268e-01, -4.9032e-01,\n",
       "        -1.4126e-01, -1.3073e-01, -3.9658e-01,  3.9287e-01, -5.4723e-02,\n",
       "        -2.8942e-01,  1.5683e-01, -4.5321e-02,  5.1924e-01,  1.1278e-01,\n",
       "        -2.3115e-02,  8.8244e-02,  6.7115e-02, -8.0355e-01, -4.5642e-01,\n",
       "         4.7945e-01,  3.2196e-01, -3.4401e-01, -3.3807e-01,  3.0307e-01,\n",
       "        -5.2028e-02,  1.2496e-01, -3.7958e-01, -5.1109e-01, -2.4140e-01,\n",
       "        -5.3661e-01, -9.5835e-02,  1.4447e-01, -5.7779e-02, -3.5680e-01,\n",
       "        -3.0390e-01,  3.9665e-02, -2.0789e-01, -6.4492e-02, -4.1587e-01,\n",
       "        -7.0349e-01,  8.9466e-02,  1.4649e-01, -5.7112e-01, -5.8508e-01,\n",
       "         3.2613e-01, -1.6048e-01,  7.7892e-02, -6.1548e-01,  3.0104e-01,\n",
       "         4.7676e-01, -6.6555e-01, -4.2913e-01, -4.8584e-01, -3.2862e-01,\n",
       "        -4.1358e-01,  6.1551e-01,  5.9599e-01, -5.9541e-01,  6.9646e-02,\n",
       "        -5.4522e-01, -5.7483e-01, -2.9061e-01,  1.0843e-02, -8.8973e-01,\n",
       "        -2.5731e-01, -8.8707e-02,  3.5480e-01, -2.9913e-01, -2.8007e-01,\n",
       "         2.1810e-01,  6.5293e-02, -8.2480e-03, -1.9519e-01, -2.6646e-02,\n",
       "         3.8274e-01,  3.9106e-01, -6.2203e-02, -3.2634e-01,  5.9647e-01,\n",
       "        -2.2446e-01, -2.0495e-01,  8.0723e-01,  6.9447e-02, -1.9899e-01,\n",
       "        -1.2892e-01,  2.5382e-01,  2.3902e-02, -3.4209e-01,  1.5925e-01,\n",
       "         8.9057e-01, -2.0449e-02, -4.2611e-01, -5.0351e-01, -7.1091e-02,\n",
       "        -1.6857e-01, -1.7324e-02,  6.9959e-03, -3.0363e-01,  6.9175e-02,\n",
       "        -8.0274e-01, -8.5393e-02, -3.5877e-01, -3.7409e-02, -4.8186e-01,\n",
       "         5.0162e-02, -6.1618e-01,  9.6746e-02,  2.2207e-01,  5.6593e-02,\n",
       "        -6.9268e-03,  2.7673e-01, -4.9957e-01,  3.3018e-02, -1.7168e-01,\n",
       "        -3.1106e-02,  7.4895e-02,  5.5752e-02,  1.3017e-01,  2.4430e-01,\n",
       "         3.8293e-01,  3.8207e-02,  9.5653e-02,  8.2624e-02,  2.3661e-01,\n",
       "         8.3943e-02,  3.4053e-01, -3.0911e-01, -6.1754e-01, -8.6886e-01,\n",
       "        -5.4596e-03, -1.9483e-01, -1.6131e-01,  2.8027e-01, -1.9182e-01,\n",
       "        -5.5910e-01,  2.0586e-01, -2.9736e-01, -8.4411e-01,  2.5031e-01,\n",
       "        -1.5828e-01,  2.6812e-01, -9.0936e-01, -4.0052e-01,  9.5588e-02,\n",
       "         9.7157e-02, -6.7439e-01,  4.5463e-02, -2.5778e-01,  4.2958e-01,\n",
       "         2.7912e-01,  2.5465e-01, -1.3854e-01,  2.1837e-01,  1.1203e-01,\n",
       "         6.1829e-01, -1.0179e-01,  2.5923e-01, -4.1219e-01,  3.8375e-01,\n",
       "        -8.3775e-02, -1.0908e-02,  7.0246e-01,  2.8020e-01,  3.1138e-01,\n",
       "        -1.2029e-01, -2.9413e-01,  3.3584e-01, -4.2189e-01,  4.2235e-01,\n",
       "        -4.6120e-01,  1.6773e-01,  2.3015e-01,  9.5494e-02,  2.9422e-01,\n",
       "         3.6491e-01,  1.4685e-01,  8.0269e-02,  3.9164e-01,  2.5412e-02,\n",
       "         1.2016e-01, -2.0403e-02, -3.8911e-02, -4.8712e-01, -2.0037e-01,\n",
       "        -8.6349e-01,  1.2734e-01, -5.8658e-01,  4.3827e-01, -4.0183e-01,\n",
       "        -5.2112e-01,  3.8415e-01,  4.2953e-05,  6.2751e-02,  7.6938e-01,\n",
       "         4.6407e-02,  3.7151e-01, -4.1942e-04, -5.5546e-01,  7.3579e-01,\n",
       "        -2.1949e-01,  2.4425e-01, -1.2826e-02, -3.2060e-03,  2.6427e-01,\n",
       "         1.0488e-01, -3.4354e-01, -4.4857e-01,  9.1539e-03,  3.0859e-01,\n",
       "         1.1488e-01, -1.5712e-01,  7.4304e-03, -1.8401e-02,  1.6647e-01,\n",
       "         8.5991e-01,  3.4457e-01, -4.8001e-01,  3.8755e-01,  3.4391e-01,\n",
       "        -1.4066e-01, -1.5236e-01,  1.6234e-01,  2.4093e-01,  7.6134e-02,\n",
       "         1.1733e-02, -1.1924e+00, -5.2931e-01,  2.3200e-01,  8.0968e-02,\n",
       "         3.8111e-01, -4.6807e-01, -1.9129e-01,  8.3324e-01,  2.5961e-01,\n",
       "         4.5225e-01,  2.0019e-01, -6.7914e-02, -2.4688e-01, -4.2694e-01,\n",
       "        -4.0023e-01, -2.8254e-01, -1.7132e-01, -1.6604e-01, -5.1278e-01,\n",
       "        -4.4860e-01, -3.6082e-01, -6.4014e-01, -4.4602e-01,  9.5946e-03,\n",
       "         5.0011e-01,  3.7499e-01,  5.9492e-02,  6.9679e-02,  4.3096e-01,\n",
       "         2.6331e-01,  2.7255e-01, -6.4100e-01, -1.7420e-01,  2.8565e-01,\n",
       "         2.2576e-01,  8.7452e-02,  6.2069e-02,  4.8623e-01, -7.7429e-02,\n",
       "        -4.2985e-01,  2.4415e-01, -3.6265e-01, -2.9267e-01, -2.2262e-01,\n",
       "         3.1439e-01,  1.8444e-01, -2.8767e-01, -9.2533e-02, -3.0134e-01,\n",
       "         4.6152e-01,  3.2864e-01,  3.1094e-03,  7.7894e-02, -4.5061e-01,\n",
       "        -5.5509e-01, -9.8959e-02, -4.8416e-01, -1.4147e-01,  4.4373e-01,\n",
       "         8.8925e-02, -2.1669e-01,  3.6456e-02,  1.5812e-02, -6.2106e-02,\n",
       "         6.6999e-01, -1.3996e-01,  2.4789e-01, -2.5960e-01, -5.1536e-01,\n",
       "        -1.5585e-01, -6.0144e-01, -5.6182e-01, -9.4438e+00, -9.2495e-02,\n",
       "         1.1934e-01, -3.8817e-02,  2.7584e-01, -3.4873e-01,  1.3457e-01,\n",
       "        -1.7263e-02, -5.7470e-01, -2.9143e-01, -2.1185e-02,  3.6106e-01,\n",
       "         4.9483e-02,  5.8487e-01,  5.9470e-01,  1.1067e-01,  5.9001e-01,\n",
       "         2.4490e-01,  2.7991e-01,  4.5470e-02,  1.6347e-01, -1.0438e+00,\n",
       "         3.7623e-01, -1.5597e-01,  4.9149e-01,  3.7232e-01,  3.9617e-01,\n",
       "         2.8114e-01, -6.7189e-01,  5.2382e-01, -3.1852e-01, -4.5428e-02,\n",
       "         3.4192e-01,  1.1727e+00,  1.3222e-01, -3.9030e-01, -4.8388e-01,\n",
       "        -2.4919e-01,  5.8718e-01, -7.6944e-02, -1.5627e-03,  2.8261e-01,\n",
       "        -1.0052e-01,  2.9304e-01,  1.0420e+00,  1.9676e-01, -1.6586e-01,\n",
       "         5.4127e-02, -2.4964e-01,  7.0022e-03, -4.5972e-01,  2.7569e-01,\n",
       "        -3.9024e-01, -6.6965e-02, -3.6583e-02, -2.7955e-01,  3.4118e-01,\n",
       "         5.5789e-01, -9.3934e-02,  1.8984e-01, -1.3725e-01, -1.8658e-01,\n",
       "         1.6210e-02, -6.6978e-03, -4.0909e-01, -2.2541e-02, -1.0593e-02,\n",
       "        -1.5296e-01,  8.3160e-03, -7.7724e-02,  1.0914e-01, -8.2271e-02,\n",
       "         4.0846e-01, -1.5030e+00, -2.0750e-01, -5.2478e-01,  3.6981e-01,\n",
       "         4.7938e-01,  2.1215e-01, -4.7085e-01, -7.4194e-02, -6.2472e-01,\n",
       "         1.7428e-01, -3.7549e-01, -3.6238e-01,  1.3142e-02,  3.0476e-01,\n",
       "        -2.9114e-01, -4.2062e-01, -7.6881e-02,  2.4500e-01,  4.0971e-01,\n",
       "         4.9701e-01,  7.1029e-01, -3.0533e-01, -7.8246e-01,  3.2517e-01,\n",
       "        -7.0217e-01, -6.2277e-01,  1.1819e-01, -3.2263e-01,  1.4099e-01,\n",
       "        -2.9428e-02,  6.5563e-01, -3.1738e-01, -5.9353e-02, -2.7229e-01,\n",
       "        -1.0257e-01, -2.4176e-01,  2.0930e-01,  7.5367e-01, -1.5359e-01,\n",
       "         3.4445e-01, -1.8762e-01,  9.3859e-02,  2.9276e-01,  3.0696e-01,\n",
       "        -1.4114e-01, -3.4003e-01, -2.3574e-01,  8.9664e-02, -1.8745e-01,\n",
       "        -2.2095e-01, -2.2513e-01, -3.2054e-01,  2.4016e-01, -3.4204e-01,\n",
       "         3.3981e-02, -1.6191e-01, -1.2630e-02, -2.2008e-01, -4.0741e-02,\n",
       "        -4.1614e-01,  4.4818e-01, -1.6056e-01, -1.3446e-01,  2.5953e-01,\n",
       "        -4.1697e-01,  2.9173e-01,  3.4947e-01,  3.0257e-01,  8.0813e-01,\n",
       "         3.3255e-01, -1.6223e-01, -2.9211e-01, -2.0288e-01,  4.9490e-01,\n",
       "         1.7194e-01,  2.7353e-01,  1.9434e-01, -5.1231e-01, -2.7310e-01,\n",
       "        -1.9963e-02,  2.0948e-01, -1.8527e-01,  3.2346e-01,  5.3749e-01,\n",
       "        -4.1152e-01, -7.5498e-01, -3.7751e-01,  2.5976e-01,  4.4203e-01,\n",
       "        -1.4671e-01,  4.5669e-01,  1.8842e-01,  3.1955e-01, -7.0591e-02,\n",
       "         6.7854e-02,  3.6167e-01, -7.6288e-02, -5.1360e-01,  4.7441e-01,\n",
       "        -1.1628e-01,  1.5839e-02,  4.5622e-01,  1.9532e-01, -1.5746e-01,\n",
       "        -2.5162e-01, -2.5981e-01,  8.9758e-02,  4.8029e-01,  1.4355e-01,\n",
       "        -6.4749e-01,  3.2758e-01,  5.3912e-01,  6.0727e-01, -5.8115e-01,\n",
       "        -2.8904e-01,  4.1059e-01, -1.8105e-02, -1.3787e-01,  2.9352e-02,\n",
       "        -1.1532e-01,  2.7661e-01, -1.8251e-01, -4.5614e-01,  4.3963e-01,\n",
       "        -4.8559e-01,  5.6115e-02,  5.3919e-01,  5.7032e-02, -1.2988e-01,\n",
       "         4.4506e-01, -3.3876e-01, -3.1521e-01,  1.0649e-01,  1.2092e-01,\n",
       "         2.1825e-01, -3.7826e-01,  2.3987e-01, -3.4509e-01, -4.0050e-01,\n",
       "        -4.8468e-01,  2.4061e-01, -2.7780e-02,  1.3121e-01, -3.1782e-01,\n",
       "        -2.5002e-01, -5.1833e-01,  5.4098e-01, -1.3526e-01,  1.5660e-01,\n",
       "        -4.1146e-01,  3.2971e-01, -3.4285e-01, -7.7709e-01,  3.6390e-01,\n",
       "        -9.6884e-02, -3.8049e-01, -3.1744e-01, -3.5588e-01, -1.1526e+00,\n",
       "         3.2982e-01, -4.3578e-02,  1.5411e-01,  7.8643e-01, -3.4693e-01,\n",
       "        -2.5570e-01,  1.6572e-01, -6.5361e-01, -1.0436e+00,  3.4484e-01,\n",
       "         5.9014e-03, -2.0755e-01,  2.8076e-02,  1.9936e-01, -3.0088e-01,\n",
       "         4.5065e-01,  7.0911e-02,  3.2447e-01, -2.4016e-01,  4.5106e-01,\n",
       "        -2.4575e-01, -1.2155e-01,  2.3876e-01, -9.1411e-01,  2.0756e-01,\n",
       "        -8.2640e-01, -4.3892e-01,  1.9177e-01, -1.8619e-01, -4.5799e-01,\n",
       "         2.3366e-01,  2.4326e-01, -1.3574e-01, -5.7964e-02,  8.2986e-02,\n",
       "         2.7222e-01,  1.0353e-02, -5.7017e-01,  1.0131e-01, -6.9741e-02,\n",
       "        -1.4712e-01,  2.2163e-01,  2.4572e-01, -2.6165e-02, -5.0719e-01,\n",
       "        -5.6757e-01,  1.7264e-02,  8.7094e-02, -2.9707e-01, -8.9971e-01,\n",
       "         5.8826e-01,  2.5130e-01, -1.6199e-01, -1.6181e-01, -6.1367e-01,\n",
       "         8.6741e-01,  4.5407e-01,  2.1348e-01,  4.8119e-01,  1.1689e-02,\n",
       "        -1.5995e-01, -4.4231e-01, -5.6337e-01, -1.8101e-01,  5.5461e-01,\n",
       "        -6.0142e-01, -1.2580e-01,  6.5202e-01,  1.9372e-01, -1.7324e-01,\n",
       "         4.0420e-01,  2.3633e-01, -2.5870e-01,  4.3831e-01,  2.9271e-01,\n",
       "        -5.4287e-01,  2.6588e-01, -3.8492e-01, -6.1342e-02, -1.0670e-02,\n",
       "        -1.7706e-01,  2.5871e-01, -5.9654e-01, -3.7969e-01, -3.1568e-01,\n",
       "         1.2829e-01,  4.7453e-02,  3.9513e-01,  5.9613e-01,  2.6132e-01,\n",
       "         2.6708e-01, -5.4631e-01,  1.8835e-01,  4.3052e-01,  1.1557e-01,\n",
       "        -2.6581e-01,  4.0736e-01,  3.1912e-01, -4.4840e-02, -4.6764e-02,\n",
       "        -2.6400e-01, -3.5295e-01,  8.4930e-02, -4.1640e-01, -1.7600e-01,\n",
       "        -1.4009e-01,  2.2806e-01, -1.2815e-01,  8.8837e-02, -4.8687e-01,\n",
       "         9.8506e-01,  4.8254e-01,  2.7713e-01,  9.7802e-02, -3.9173e-01,\n",
       "        -2.3532e-01,  2.9253e-01,  9.3842e-01,  3.8688e-01, -3.9707e-01,\n",
       "         2.0418e-01, -1.8391e-01,  4.4809e-01,  9.6689e-02, -1.2599e-02,\n",
       "         7.8991e-01,  7.4097e-02,  9.5320e-01,  3.4444e-01, -2.5998e-01,\n",
       "        -3.6352e-02, -6.3022e-01,  4.1133e-01, -4.6186e-02,  7.0394e-01,\n",
       "        -5.6990e-02, -1.0934e-01, -1.4107e-01,  2.6034e-01, -1.3228e-01,\n",
       "         7.4290e-01, -6.1378e-01,  2.1685e-01,  5.2676e-01,  1.7752e-01,\n",
       "        -2.4050e-01,  1.7293e-01,  4.0926e-01,  9.6105e-02,  3.7872e-01,\n",
       "        -8.0730e-01, -7.0151e-01, -3.0986e-01,  7.4947e-02, -4.6726e-01,\n",
       "        -1.2997e-01,  3.6378e-01, -8.8217e-02,  2.5279e-01,  1.0991e-01,\n",
       "         2.2144e-01, -1.8319e-02,  4.4327e-01, -2.6436e-02, -6.1456e-03,\n",
       "         9.0005e-02,  1.9745e-01, -3.5065e-01,  3.4040e-01,  2.4300e-01,\n",
       "        -1.5635e-01,  5.7664e-01, -4.5654e-02,  1.8105e-02, -3.9562e-01,\n",
       "         5.4336e-01, -3.8084e-01, -3.9969e-01,  5.3255e-01,  9.0817e-01,\n",
       "         1.8417e-02,  6.9083e-01,  3.9245e-01, -2.7063e-01,  1.6917e-01,\n",
       "        -3.8812e-01, -5.7313e-01,  1.3005e-01, -6.3706e-01, -4.2705e-01,\n",
       "         2.0127e-01, -3.7138e-01,  4.6015e-02, -3.0431e-01, -3.0268e-01,\n",
       "        -2.0090e-01, -8.9865e-03, -2.8009e-01, -1.9668e-01,  3.6393e-01,\n",
       "         4.2629e-01,  1.0644e-02, -2.1528e-01,  1.4366e-01,  1.7066e-01,\n",
       "        -7.9158e-03, -2.0773e-01,  1.8148e-01, -3.0152e-01, -2.0370e-01,\n",
       "         2.1591e-01, -7.7172e-01,  2.7605e-01,  1.3086e-01,  1.2740e-01,\n",
       "        -6.3871e-01, -3.4123e-01, -4.8405e-01, -1.6540e-01,  3.1282e-02,\n",
       "         3.0352e-01,  1.3740e-01,  2.9939e-01, -2.3157e-01, -3.3319e-01,\n",
       "        -1.0414e+00,  4.3010e-01, -1.7616e-01])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 the\n",
      "2 financial\n",
      "3 performance\n",
      "4 of\n",
      "5 the\n",
      "6 company\n",
      "7 was\n",
      "8 average\n",
      "9 overall\n",
      "10 ,\n",
      "11 but\n",
      "12 revenue\n",
      "13 spiked\n",
      "14 by\n",
      "15 a\n",
      "16 lot\n",
      "17 there\n",
      "18 was\n",
      "19 a\n",
      "20 dip\n",
      "21 in\n",
      "22 the\n",
      "23 net\n",
      "24 profit\n",
      "25 margin\n",
      "26 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    print(i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 vector values for \"revenue\", \"profit\" and \"margin\" are:\n",
      "\n",
      "revenue    tensor([ 1.0783, -0.0221,  2.7635, -0.0498,  2.1201])\n",
      "profit   tensor([ 0.8338, -0.5861,  2.2561,  1.6393,  0.5799])\n",
      "margin    tensor([-0.7424, -3.2827,  0.3892,  0.7105, -2.7882])\n"
     ]
    }
   ],
   "source": [
    "print('First 5 vector values for \"revenue\", \"profit\" and \"margin\" are:')\n",
    "print('')\n",
    "print(\"revenue   \", str(token_vecs_sum[12][:5]))\n",
    "print(\"profit  \", str(token_vecs_sum[24][:5]))\n",
    "print(\"margin   \", str(token_vecs_sum[25][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity:  0.70\n",
      "Vector similarity:  0.50\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word revenue and profit\n",
    "one = 1 - cosine(token_vecs_sum[12], token_vecs_sum[24])\n",
    "\n",
    "# Calculate the cosine similarity between the word revenue and margin\n",
    "two = 1 - cosine(token_vecs_sum[12], token_vecs_sum[25])\n",
    "\n",
    "print('Vector similarity:  %.2f' % one)\n",
    "print('Vector similarity:  %.2f' % two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Image from [Jay Allamar](http://jalammar.github.io/illustrated-bert/)'s blog)\n",
    "\n",
    "\n",
    "![alt text](http://jalammar.github.io/images/bert-feature-extraction-contextualized-embeddings.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
